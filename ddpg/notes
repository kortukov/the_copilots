# Slurm interactive job with 1 gpu
srun -p a100 --ntasks=1 --cpus-per-task=4 --mem=10G --time=0-04:00 --gres=gpu:1  --pty bash 

# Slurm run job in the background
srun --job-name "train" -p gpu-2080ti --ntasks=1 --cpus-per-task=32 --mem=20G --time=0-14:00 --gres=gpu:1 --output=0_out_train --error=0_err_train sh -c "source ~/.bashrc && conda activate rl && python  train.py -e HalfCheetah-v4 -m 10000 --results-dir results" &

srun --job-name "train_1" -p gpu-2080ti --ntasks=1 --cpus-per-task=32 --mem=20G --time=0-14:00 --gres=gpu:1 --output=1_out_train --error=1_err_train sh -c "source ~/.bashrc && conda activate rl && python  train.py -e HalfCheetah-v4 -m 10000  --results-dir results_1" &

srun --job-name "train_2" -p gpu-2080ti --ntasks=1 --cpus-per-task=32 --mem=20G --time=0-14:00 --gres=gpu:1 --output=2_out_train --error=2_err_train sh -c "source ~/.bashrc && conda activate rl && python  train.py -e HalfCheetah-v4 -m 10000  --results-dir results_2" &


# Slurm run job with sbatch (preferred) replace 0 with some integer
sbatch -J 0 --no-requeue slurm_train.sh
